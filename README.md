# ğŸ™ï¸ Podcast AI

**Podcast AI** is an AI-driven platform that converts research papers (e.g., from ArXiv) into podcast-like narratives. Key features include secure user authentication, automated PDF parsing, script generation via LLM, and dynamic prompt orchestration through MCP.

---

## ğŸ” Tech Overview

- **Backend**: FastAPI (Python)  
- **Auth**: JWT for secure login/signup flows  
- **PDF â†’ Markdown**: Extract content using libraries like PyMuPDF or PDFMiner  
- **LLM Integration**: Use *Mistral* for content summarization and markdown conversion  
- **Script Generation**: Custom logic to create engaging, conversational narration  
- **Prompts Management**: Prompts are stored and fetched remotely using the **Model Context Protocol (MCP)**, enabling version control and easy updates 

---

## âš™ï¸ Why MCP?

The *Model Context Protocol (MCP)* is an **open standard** introduced by Anthropic in November 2024. It allows LLM-powered apps to:
1. Discover available tools or prompts  
2. Fetch structured prompt templates via JSONâ€‘RPC  
3. Maintain modular and updateable prompt logic separate from code  
[oai_citation: en.wikipedia.org](https://en.wikipedia.org/wiki/Model_Context_Protocol?utm_source=chatgpt.com)
[oai_citation: medium.com](https://medium.com/ai-cloud-lab/model-context-protocol-mcp-with-ollama-a-full-deep-dive-working-code-part-1-81a3bb6d16b3?utm_source=chatgpt.com) 
[oai_citation: blog.miloslavhomer.cz](https://blog.miloslavhomer.cz/p/tools-for-mistral-model-context-protocol?utm_source=chatgpt.com)

MCP is widely adopted by OpenAI, Google DeepMind, Microsoft, and many others as the â€œUSBâ€‘C for AI appsâ€  

---

## ğŸ—ï¸ Architecture

```
User â†’ FastAPI Endpoints â†’ PDF Fetcher â†’ Markdown Extractor â†’
Mistral LLM â†’ Script Generator â†’ Output ğŸ™ï¸
â†‘
Prompts from MCP Server
```

---

## âœ… Feature List

- **JWT-Based Authentication**  
- **Paper Ingestion**: Submit ArXiv URLs or PDFs  
- **PDF â†’ Markdown Extraction**  (Mistral OCR)
- **Mistral-Powered LLM** summarizing markdown into scripts  
- **Prompt Orchestration** with MCP server â€“ remote fetch and version control  
- **Custom Narration Styles** â€“ default presets + user-defined options  

---

## ğŸ§‘â€ğŸ’» Setup & Run

```bash
git clone https://github.com/â€¦/PodcastAI.git
cd PodcastAI

python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

uvicorn app.main:app --reload
```

## Backend

### Authentication flow

```bash
POST /auth/login
{
  "username": "your_user",
  "password": "secure_pass"
}
# â†’ { "access_token": "jwt-token" }

GET /papers?url=https://arxiv.org/abs/â€¦
Authorization: Bearer <jwt-token>
```
## ğŸ§  LLM + MCP Prompting
- MCP Client in your backend auto-discovers prompt templates.
- Makes JSON-RPC call to MCP server to get best practice and latest prompts.
- Sends paperâ€™s markdown + prompt to Mistral to generate natural-language script.
- MCP centralizes prompt updatesâ€”improve narrator style without backend changes

## ğŸ“¦ Sample Request & Response
```bash
POST /papers/request
Content-Type: application/json
Authorization: Bearer <token>

{
  "arxiv_url": "https://arxiv.org/abs/1706.03762",
  "style_id": "concise_explainer"
}
---
200 OK
{
  "script": "In this episode, we explore the Transformer architecture introduced in 2017..."
}
```

### ğŸ“Œ Roadmap
- ğŸ—£ï¸ TTS Integration (e.g., ElevenLabs, Bark)
- ğŸ” Job orchestration: background tasks with Celery or RQ
- ğŸ§‘â€ğŸ“ Frontend/UI with live progress (FastAPI + WebSockets/Streamlit)
- ğŸ§ Podcast Publishing: export to RSS, audio stores